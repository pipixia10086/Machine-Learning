{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def toy_dataset(total_clusters=2, sample_per_cluster=50):\n",
    "    # TODO: add sample size ease\n",
    "    np.random.seed(int(time.time()))\n",
    "    N = total_clusters * sample_per_cluster\n",
    "    y = np.zeros(N)\n",
    "    np.random.seed(43)\n",
    "    x = np.random.standard_normal(size=(N, 2))\n",
    "    for i in range(total_clusters):\n",
    "        theta = 2*np.pi*i / total_clusters\n",
    "        x[i*sample_per_cluster:(i+1)*sample_per_cluster] = x[i*sample_per_cluster:(i+1)*sample_per_cluster] + \\\n",
    "            (total_clusters * np.cos(theta), total_clusters * np.sin(theta))\n",
    "        y[i*sample_per_cluster:(i+1)*sample_per_cluster] = i\n",
    "\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def load_digits():\n",
    "    digits = datasets.load_digits()\n",
    "    x = digits.data/16\n",
    "    x = x.reshape([x.shape[0], -1])\n",
    "    y = digits.target\n",
    "    \n",
    "    return train_test_split(x, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_cluster = 50\n",
    "n_cluster = 9\n",
    "x, y = toy_dataset(n_cluster, samples_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_means_plus_plus_center_indices(n, n_cluster, x, generator=np.random):\n",
    "    first_center = x[generator.randint(0, n - 1)]\n",
    "    centers = [first_center]\n",
    "    for i in range(n_cluster - 1):\n",
    "        distance = []\n",
    "        for point in x:\n",
    "            local_min = float('inf')\n",
    "            for center in centers:\n",
    "                local_min = min(np.sqrt(np.sum(np.power((point - center), 2))), local_min)\n",
    "            distance.append(local_min)\n",
    "        centers.append(x[np.argmax(distance)])\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_k_means_plus_plus_center_indices(len(x), n_cluster, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-8.60519634, -3.9717283 ]),\n",
       " array([9.51184262, 7.29385686]),\n",
       " array([ 6.74524742, -7.82711022]),\n",
       " array([-4.60302021,  9.29916152]),\n",
       " array([11.08905957, -1.01270925]),\n",
       " array([ -0.6433554 , -10.48227706]),\n",
       " array([-9.71095466,  3.62798132]),\n",
       " array([2.51166286, 9.62309962]),\n",
       " array([4.78520657, 4.26597288])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-9.0373166 ,  4.0837211 ]],\n",
       "\n",
       "       [[ 0.39073705,  7.10299333]],\n",
       "\n",
       "       [[ 8.9098984 ,  4.75364035]],\n",
       "\n",
       "       [[ 7.02423461,  5.71985062]],\n",
       "\n",
       "       [[ 9.39490664,  0.83720502]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = x[np.random.choice(500, 5, replace=False)]\n",
    "b = np.expand_dims(b, axis=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.power(c, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.sum(c, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 65.07699297, 354.37627941, 390.95722978,  46.86380324,\n",
       "        431.04462031, 282.62688687,   0.66148697, 164.06364112,\n",
       "        191.09536261],\n",
       "       [203.57627673,  83.2309956 , 263.28779383,  29.76076632,\n",
       "        180.31873311, 310.31108163, 114.11988386,  10.84926203,\n",
       "         27.36004734],\n",
       "       [382.91060201,   6.81503674, 162.96099882, 203.2607321 ,\n",
       "         37.99953121, 323.39783763, 348.00327701,  64.64905161,\n",
       "         17.25090228],\n",
       "       [338.2058139 ,   8.66568923, 183.59798177, 148.00452125,\n",
       "         61.8501644 , 321.3008779 , 284.44247715,  35.5986566 ,\n",
       "          7.12700705],\n",
       "       [347.12954685,  41.70202699,  82.09105255, 267.5466637 ,\n",
       "          6.292337  , 228.89737932, 372.82236819, 124.57098877,\n",
       "         33.00578373]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 1, 4, 4, 0, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lloyd_k_means(n, n_cluster, x, generator):\n",
    "    return generator.choice(n, size=n_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "\n",
    "    '''\n",
    "        Class KMeans:\n",
    "        Attr:\n",
    "            n_cluster - Number of cluster for kmeans clustering (Int)\n",
    "            max_iter - maximum updates for kmeans clustering (Int)\n",
    "            e - error tolerance (Float)\n",
    "            generator - random number generator from 0 to n for choosing the first cluster at random\n",
    "            The default is np.random here but in grading, to calculate deterministic results,\n",
    "            We will be using our own random number generator.\n",
    "    '''\n",
    "    def __init__(self, n_cluster, max_iter=100, e=0.0001, generator=np.random):\n",
    "        self.n_cluster = n_cluster\n",
    "        self.max_iter = max_iter\n",
    "        self.e = e\n",
    "        self.generator = generator\n",
    "\n",
    "    def fit(self, x, centroid_func=get_lloyd_k_means):\n",
    "\n",
    "        '''\n",
    "            Finds n_cluster in the data x\n",
    "            params:\n",
    "                x - N X D numpy array\n",
    "                centroid_func - To specify which algorithm we are using to compute the centers(Lloyd(regular) or Kmeans++)\n",
    "            returns:\n",
    "                A tuple\n",
    "                (centroids a n_cluster X D numpy array, y a length (N,) numpy array where cell i is the ith sample's assigned cluster, number_of_updates a Int)\n",
    "            Note: Number of iterations is the number of time you update the assignment\n",
    "        '''\n",
    "        assert len(x.shape) == 2, \"fit function takes 2-D numpy arrays as input\"\n",
    "        \n",
    "        N, D = x.shape\n",
    "\n",
    "        self.centers = centroid_func(len(x), self.n_cluster, x, self.generator)\n",
    "\n",
    "        # TODO:\n",
    "        # - comment/remove the exception.\n",
    "        # - Initialize means by picking self.n_cluster from N data points\n",
    "        # - Update means and membership until convergence or until you have made self.max_iter updates.\n",
    "        # - return (means, membership, number_of_updates)\n",
    "\n",
    "        # DONOT CHANGE CODE ABOVE THIS LINE\n",
    "            \n",
    "        r = np.zeros(N, dtype=int)\n",
    "        J = np.inf\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            l2 = np.sum( np.power((x-np.expand_dims(self.centers, axis=1)), 2),  axis=2)\n",
    "            r = np.argmin(l2, axis=0)\n",
    "            # calculate distortion\n",
    "            J_new = np.sum([np.sum((x[r == k] - self.centers[k]) ** 2) for k in range(self.n_cluster)]) / N\n",
    "            \n",
    "            if np.abs(J - J_new) < self.e:\n",
    "                break\n",
    "            J = J_new\n",
    "            # update mean\n",
    "            self.centers = [np.mean(x[r == k], axis=0) for k in range(self.n_cluster)]        \n",
    "        \n",
    "        \n",
    "        centroids = self.centers\n",
    "        y = [  x[r == k] for k in range(self.n_cluster)]\n",
    "        self.max_iter = i\n",
    "        \n",
    "        # DO NOT CHANGE CODE BELOW THIS LINE\n",
    "        return centroids, y, self.max_iter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansClassifier():\n",
    "\n",
    "    '''\n",
    "        Class KMeansClassifier:\n",
    "        Attr:\n",
    "            n_cluster - Number of cluster for kmeans clustering (Int)\n",
    "            max_iter - maximum updates for kmeans clustering (Int)\n",
    "            e - error tolerance (Float)\n",
    "            generator - random number generator from 0 to n for choosing the first cluster at random\n",
    "            The default is np.random here but in grading, to calculate deterministic results,\n",
    "            We will be using our own random number generator.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, n_cluster, max_iter=100, e=1e-6, generator=np.random):\n",
    "        self.n_cluster = n_cluster\n",
    "        self.max_iter = max_iter\n",
    "        self.e = e\n",
    "        self.generator = generator\n",
    "\n",
    "\n",
    "    def fit(self, x, y, centroid_func=get_lloyd_k_means):\n",
    "        '''\n",
    "            Train the classifier\n",
    "            params:\n",
    "                x - N X D size  numpy array\n",
    "                y - (N,) size numpy array of labels\n",
    "                centroid_func - To specify which algorithm we are using to compute the centers(Lloyd(regular) or Kmeans++)\n",
    "\n",
    "            returns:\n",
    "                None\n",
    "            Stores following attributes:\n",
    "                self.centroids : centroids obtained by kmeans clustering (n_cluster X D numpy array)\n",
    "                self.centroid_labels : labels of each centroid obtained by\n",
    "                    majority voting (N,) numpy array)\n",
    "        '''\n",
    "\n",
    "        assert len(x.shape) == 2, \"x should be a 2-D numpy array\"\n",
    "        assert len(y.shape) == 1, \"y should be a 1-D numpy array\"\n",
    "        assert y.shape[0] == x.shape[0], \"y and x should have same rows\"\n",
    "\n",
    "        self.generator.seed(42)\n",
    "        N, D = x.shape\n",
    "        # TODO:\n",
    "        # - comment/remove the exception.\n",
    "        # - Implement the classifier\n",
    "        # - assign means to centroids\n",
    "        # - assign labels to centroid_labels\n",
    "\n",
    "        # DONOT CHANGE CODE ABOVE THIS LINE\n",
    "        raise Exception(\n",
    "             'Implement fit function in KMeansClassifier class')\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # DONOT CHANGE CODE BELOW THIS LINE\n",
    "\n",
    "        self.centroid_labels = centroid_labels\n",
    "        self.centroids = centroids\n",
    "\n",
    "        assert self.centroid_labels.shape == (\n",
    "            self.n_cluster,), 'centroid_labels should be a numpy array of shape ({},)'.format(self.n_cluster)\n",
    "\n",
    "        assert self.centroids.shape == (\n",
    "            self.n_cluster, D), 'centroid should be a numpy array of shape {} X {}'.format(self.n_cluster, D)\n",
    "\n",
    "    def predict(self, x):\n",
    "        '''\n",
    "            Predict function\n",
    "            params:\n",
    "                x - N X D size  numpy array\n",
    "            returns:\n",
    "                predicted labels - numpy array of size (N,)\n",
    "        '''\n",
    "\n",
    "        assert len(x.shape) == 2, \"x should be a 2-D numpy array\"\n",
    "\n",
    "        self.generator.seed(42)\n",
    "        N, D = x.shape\n",
    "        # TODO:\n",
    "        # - comment/remove the exception.\n",
    "        # - Implement the prediction algorithm\n",
    "        # - return labels\n",
    "\n",
    "        # DONOT CHANGE CODE ABOVE THIS LINE\n",
    "        raise Exception(\n",
    "             'Implement predict function in KMeansClassifier class')\n",
    "        \n",
    "        \n",
    "        # DO NOT CHANGE CODE BELOW THIS LINE\n",
    "        return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_loader import toy_dataset, load_digits\n",
    "from kmeans import KMeans, KMeansClassifier, get_k_means_plus_plus_center_indices as k_plus, get_lloyd_k_means as k_vanilla, transform_image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from utils import Figure\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_toy():\n",
    "    print(\"[+] K-Means on Toy Dataset\")\n",
    "\n",
    "    print(\"[+] K-Means Vanilla\")\n",
    "    kmeans_builder(k_vanilla)\n",
    "    print()\n",
    "\n",
    "    print(\"[+] K-Means Plus Plus\")\n",
    "    kmeans_builder(k_plus)\n",
    "    print()\n",
    "\n",
    "\n",
    "def kmeans_builder(centroid_func):\n",
    "    samples_per_cluster = 50\n",
    "    n_cluster = 9\n",
    "\n",
    "    x, y = toy_dataset(n_cluster, samples_per_cluster)\n",
    "    fig = Figure()\n",
    "    fig.ax.scatter(x[:, 0], x[:, 1], c=y)\n",
    "    fig.savefig('plots/toy_dataset_real_labels.png')\n",
    "\n",
    "    fig.ax.scatter(x[:, 0], x[:, 1])\n",
    "    fig.savefig('plots/toy_dataset.png')\n",
    "\n",
    "    k_means = KMeans(n_cluster=n_cluster, max_iter=100, e=1e-8)\n",
    "\n",
    "    centroids, membership, i = k_means.fit(x, centroid_func)\n",
    "\n",
    "\n",
    "\n",
    "    assert centroids.shape == (n_cluster, 2), \\\n",
    "        ('centroids for toy dataset should be numpy array of size {} X 2'\n",
    "            .format(n_cluster))\n",
    "\n",
    "    assert membership.shape == (samples_per_cluster * n_cluster,), \\\n",
    "        'membership for toy dataset should be a vector of size {}'.format(len(membership))\n",
    "\n",
    "    assert type(i) == int and i > 0,  \\\n",
    "        'Number of updates for toy datasets should be integer and positive'\n",
    "\n",
    "    print('[success] : kmeans clustering done on toy dataset')\n",
    "    print('Toy dataset K means clustering converged in {} steps'.format(i))\n",
    "\n",
    "    fig = Figure()\n",
    "    fig.ax.scatter(x[:, 0], x[:, 1], c=membership)\n",
    "    fig.ax.scatter(centroids[:, 0], centroids[:, 1], c='red')\n",
    "    fig.savefig('plots/toy_dataset_predicted_labels.png')\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# KMeans for image compression\n",
    "# Here we use k-means for compressing an image\n",
    "# We load an image 'baboon.tiff',  scale it to [0,1] and compress it.\n",
    "# The problem can be rephrased as --- \"each pixel is a 3-D data point (RGB) and we want to map each point to N points or N clusters.\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def kmeans_image_compression():\n",
    "\n",
    "    print(\"[+] K-Means Image Compression\")\n",
    "    im = plt.imread('baboon.tiff')\n",
    "    N, M = im.shape[:2]\n",
    "    im = im / 255\n",
    "\n",
    "    # convert to RGB array\n",
    "    data = im.reshape(N * M, 3)\n",
    "\n",
    "    k_means = KMeans(n_cluster=16, max_iter=100, e=1e-6)\n",
    "    centroids, _, i = k_means.fit(data)\n",
    "\n",
    "    print('[+] RGB centroids computed in {} iteration'.format(i))\n",
    "    new_im = transform_image(im, centroids)\n",
    "\n",
    "    assert new_im.shape == im.shape, \\\n",
    "        'Shape of transformed image should be same as image'\n",
    "\n",
    "    mse = np.sum((im - new_im)**2) / (N * M)\n",
    "    print('[+] Mean square error per pixel is {}\\n'.format(mse))\n",
    "    plt.imsave('plots/compressed_baboon.png', new_im)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Kmeans for classification\n",
    "# Here we use k-means for classifying digits\n",
    "# We find N clusters in the data and label each cluster with the maximal class that belongs to that cluster.\n",
    "# Test samples are labeled based on which cluster they belong to\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def kmeans_classification():\n",
    "    print(\"[+] K-Means Classification\")\n",
    "\n",
    "    x_train, x_test, y_train, y_test = load_digits()\n",
    "\n",
    "    print(\"[+] K-Means Vanilla\")\n",
    "    kmeans_classification_builder(k_vanilla, x_train, x_test, y_train, y_test)\n",
    "    print()\n",
    "\n",
    "    print(\"[+] K-Means Plus Plus\")\n",
    "    kmeans_classification_builder(k_plus, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    linear_classifier = LogisticRegression()\n",
    "    linear_classifier.fit(x_train, y_train)\n",
    "    y_hat_test = linear_classifier.predict(x_test)\n",
    "    print('[*] Accuracy of logistic regression classifier is {}'\n",
    "          .format(np.mean(y_hat_test == y_test)))\n",
    "\n",
    "    KNNClassifier = KNeighborsClassifier()\n",
    "    KNNClassifier.fit(x_train, y_train)\n",
    "    y_hat_test = KNNClassifier.predict(x_test)\n",
    "    print('[*] Accuracy of Nearest Neighbour classifier is {}'\n",
    "          .format(np.mean(y_hat_test == y_test)))\n",
    "\n",
    "\n",
    "def kmeans_classification_builder(centroid_func, x_train, x_test, y_train, y_test):\n",
    "\n",
    "    # plot some train data\n",
    "    N = 25\n",
    "    l = int(np.ceil(np.sqrt(N)))\n",
    "\n",
    "    im = np.zeros((10 * l, 10 * l))\n",
    "    for m in range(l):\n",
    "        for n in range(l):\n",
    "            if (m * l + n < N):\n",
    "                im[10 * m:10 * m + 8, 10 * n:10 * n +\n",
    "                    8] = x_train[m * l + n].reshape([8, 8])\n",
    "    plt.imsave('plots/digits.png', im, cmap='Greys')\n",
    "\n",
    "    n_cluster = 10\n",
    "    classifier = KMeansClassifier(n_cluster=n_cluster, max_iter=100, e=1e-6)\n",
    "\n",
    "    classifier.fit(x_train, y_train, centroid_func)\n",
    "    y_hat_test = classifier.predict(x_test)\n",
    "\n",
    "    assert y_hat_test.shape == y_test.shape, \\\n",
    "        'y_hat_test and y_test should have same shape'\n",
    "\n",
    "    print('[*] Prediction accuracy of K-means classifier with {} cluster is {}'.\n",
    "          format(n_cluster, np.mean(y_hat_test == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] K-Means on Toy Dataset\n",
      "[+] K-Means Vanilla\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Implement fit function in KMeans class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-1fae9ef1fb4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeans_toy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mkmeans_image_compression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkmeans_classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-df459f88e065>\u001b[0m in \u001b[0;36mkmeans_toy\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[+] K-Means Vanilla\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mkmeans_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_vanilla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-df459f88e065>\u001b[0m in \u001b[0;36mkmeans_builder\u001b[1;34m(centroid_func)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mk_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_cluster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_cluster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mcentroids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmembership\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_means\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentroid_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google 云端硬盘\\CSCI567\\PA4\\k-mean-cluster\\kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, centroid_func)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;31m# DONOT CHANGE CODE ABOVE THIS LINE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         raise Exception(\n\u001b[1;32m---> 83\u001b[1;33m              'Implement fit function in KMeans class')\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# DO NOT CHANGE CODE BELOW THIS LINE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Implement fit function in KMeans class"
     ]
    }
   ],
   "source": [
    "kmeans_toy()\n",
    "kmeans_image_compression()\n",
    "kmeans_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
