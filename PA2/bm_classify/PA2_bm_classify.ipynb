{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def binary_train(X, y, loss=\"perceptron\", w0=None, b0=None, step_size=0.5, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: training features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - y: binary training labels, a N dimensional numpy array where \n",
    "    N is the number of training points, indicating the labels of \n",
    "    training data\n",
    "    - loss: loss type, either perceptron or logistic\n",
    "    - step_size: step size (learning rate)\n",
    "\t- max_iterations: number of iterations to perform gradient descent\n",
    "\n",
    "    Returns:\n",
    "    - w: D-dimensional vector, a numpy array which is the weight \n",
    "    vector of logistic or perceptron regression\n",
    "    - b: scalar, which is the bias of logistic or perceptron regression\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    assert len(np.unique(y)) == 2\n",
    "    \n",
    "    w = np.zeros(D)\n",
    "    if w0 is not None:\n",
    "        w = w0\n",
    "    \n",
    "    b = 0\n",
    "    if b0 is not None:\n",
    "        b = b0\n",
    "\n",
    "    if loss == \"perceptron\":\n",
    "        ############################################\n",
    "        # TODO 1 : Edit this if part               #\n",
    "        #          Compute w and b here            #\n",
    "        w = np.zeros(D)\n",
    "        b = 0\n",
    "        \n",
    "        y = 2 * y - 1 # 映射到 -1 1\n",
    "        for i in range(max_iterations):                \n",
    "            predict = X.dot(w.T) + b  # n * 1\n",
    "#             predict = np.sign(predict)\n",
    "#             err = predict - y\n",
    "            err = predict * y\n",
    "            errindex = np.where(err <= 0)\n",
    "            rightindex = np.where(err > 0)\n",
    "            err[errindex] = 1\n",
    "            err[rightindex] = 0\n",
    "            \n",
    "            w_c =  step_size * (err * y).dot(X) / N\n",
    "            b_c =  step_size * np.sum(err * y) / N\n",
    "\n",
    "            w = w + w_c\n",
    "            b = b + b_c\n",
    "#             predict = np.sign(predict)\n",
    "#             err = predict - y                                   \n",
    "#             w_c = - step_size * 2 * err.dot(X) / N\n",
    "#             b_c = - step_size * 2 * np.sum(err) / N            \n",
    "            \n",
    "            \n",
    "#             predict[np.where(predict <= 0)] = 0\n",
    "#             predict[np.where(predict > 0)] = 1\n",
    "#             err = predict - y\n",
    "#             errindex = np.where(err != 0)[0]\n",
    "#             err = err[ errindex ]\n",
    "            \n",
    "#             w_c = - step_size * err.dot(X) / N\n",
    "#             b_c = - step_size * np.sum(err) / N\n",
    "\n",
    "\n",
    "        ############################################\n",
    "        \n",
    "\n",
    "    elif loss == \"logistic\":\n",
    "        ############################################\n",
    "        # TODO 2 : Edit this if part               #\n",
    "        #          Compute w and b here            #\n",
    "        w = np.zeros(D)\n",
    "        b = 0\n",
    "        \n",
    "        for i in range(max_iterations):\n",
    "            \n",
    "            err = sigmoid(X.dot(w.T) + b) - y  # n*1\n",
    "            w_c = -step_size * err.T.dot(X)/ y.shape[0]   # 1*n   *  n*2   = 1 * 2\n",
    "            b_c = -step_size * np.sum(err) / y.shape[0]    #  1*n  * n*1\n",
    "            w = w + w_c\n",
    "            b = b + b_c\n",
    "        ############################################\n",
    "        \n",
    "\n",
    "    else:\n",
    "        raise \"Loss Function is undefined.\"\n",
    "\n",
    "    assert w.shape == (D,)\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - z: a numpy array or a float number\n",
    "    \n",
    "    Returns:\n",
    "    - value: a numpy array or a float number after computing sigmoid function value = 1/(1+exp(-z)).\n",
    "    \"\"\"\n",
    "\n",
    "    ############################################\n",
    "    # TODO 3 : Edit this part to               #\n",
    "    #          Compute value                   #\n",
    "    value = z\n",
    "    value = 1 / (1 + np.exp(-z))\n",
    "    ############################################\n",
    "    \n",
    "    return value\n",
    "\n",
    "def binary_predict(X, w, b, loss=\"perceptron\"):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: testing features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - w: D-dimensional vector, a numpy array which is the weight \n",
    "    vector of your learned model\n",
    "    - b: scalar, which is the bias of your model\n",
    "    - loss: loss type, either perceptron or logistic\n",
    "    \n",
    "    Returns:\n",
    "    - preds: N dimensional vector of binary predictions: {0, 1}\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    \n",
    "    if loss == \"perceptron\":\n",
    "        ############################################\n",
    "        # TODO 4 : Edit this if part               #\n",
    "        #          Compute preds                   #\n",
    "        preds = np.zeros(N)\n",
    "        \n",
    "        preds = w.dot(X.T) + b\n",
    "        preds[np.where(preds <= 0)] = 0\n",
    "        preds[np.where(preds > 0)] = 1\n",
    "        assert preds.shape == (N,) \n",
    "        \n",
    "        ############################################\n",
    "        \n",
    "\n",
    "    elif loss == \"logistic\":\n",
    "        ############################################\n",
    "        # TODO 5 : Edit this if part               #\n",
    "        #          Compute preds                   #\n",
    "        preds = np.zeros(N)\n",
    "        \n",
    "        preds = sigmoid(w.dot(X.T) + b)\n",
    "        preds[np.where(preds <= 0.5)] = 0\n",
    "        preds[np.where(preds > 0.5)] = 1\n",
    "        assert preds.shape == (N,)\n",
    "        ############################################\n",
    "        \n",
    "\n",
    "    else:\n",
    "        raise \"Loss Function is undefined.\"\n",
    "    \n",
    "\n",
    "    assert preds.shape == (N,) \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_blobs, make_moons, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from linear_regression import mapping_data\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Binary classification data\n",
    "def toy_data_binary():\n",
    "  data = make_classification(n_samples=500, \n",
    "                              n_features=2,\n",
    "                              n_informative=1, \n",
    "                              n_redundant=0, \n",
    "                              n_repeated=0, \n",
    "                              n_classes=2, \n",
    "                              n_clusters_per_class=1, \n",
    "                              class_sep=1., \n",
    "                              random_state=42)\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(data[0], data[1], train_size=0.7, random_state=42)\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def moon_dataset():\n",
    "  data = make_moons(n_samples=500, shuffle=True, noise=0.2, random_state=42)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(data[0], data[1], train_size=0.7, random_state=42)\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Multiple classification data\n",
    "\n",
    "def toy_data_multiclass():\n",
    "  data = make_blobs(n_samples=2000,\n",
    "                     n_features=2,\n",
    "                     random_state=42,\n",
    "                     centers=[[-0.5, 1],[0, 1.5],[0.5, 1]],\n",
    "                     cluster_std=0.2);\n",
    "  X_train, X_test, y_train, y_test = train_test_split(data[0], data[1], train_size=0.7, random_state=42)\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Hand-written digits data\n",
    "def data_loader_mnist(dataset='mnist_subset.json'):\n",
    "  # This function reads the MNIST data and separate it into train, val, and test set\n",
    "  with open(dataset, 'r') as f:\n",
    "        data_set = json.load(f)\n",
    "  train_set, valid_set, test_set = data_set['train'], data_set['valid'], data_set['test']\n",
    "\n",
    "  return np.asarray(train_set[0]), \\\n",
    "          np.asarray(test_set[0]), \\\n",
    "          np.asarray(train_set[1]), \\\n",
    "          np.asarray(test_set[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = toy_data_binary()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy的一维向量不在乎是横向量还是纵向量\n",
    "A = np.array([1,2])\n",
    "B = np.array([3,4])\n",
    "A.dot(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array(range(9))\n",
    "c = np.where(w < 5)\n",
    "c\n",
    "w[c] = 0\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def accuracy_score(true, preds):\n",
    "    return np.sum(true == preds).astype(float) / len(true)\n",
    "\n",
    "def run_binary():\n",
    "    datasets = [(toy_data_binary(), 'Synthetic data'), \n",
    "                (moon_dataset(), 'Two Moon data'),\n",
    "                (data_loader_mnist(), 'Binarized MNIST data')]\n",
    "\n",
    "    for data, name in datasets:\n",
    "        print(name)\n",
    "        X_train, X_test, y_train, y_test = data\n",
    "\n",
    "        if name == 'Binarized MNIST data':\n",
    "            y_train = [0 if yi < 5 else 1 for yi in y_train]\n",
    "            y_test = [0 if yi < 5 else 1 for yi in y_test]\n",
    "            y_train = np.asarray(y_train)\n",
    "            y_test = np.asarray(y_test)\n",
    "\n",
    "        for loss_type in [\"perceptron\", \"logistic\"]:\n",
    "            w, b = binary_train(X_train, y_train, loss=loss_type)\n",
    "            train_preds = binary_predict(X_train, w, b, loss=loss_type)\n",
    "            preds = binary_predict(X_test, w, b, loss=loss_type)            \n",
    "            print(loss_type + ' train acc: %f, test acc: %f' \n",
    "                %(accuracy_score(y_train, train_preds), accuracy_score(y_test, preds)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data\n",
      "perceptron train acc: 0.994286, test acc: 1.000000\n",
      "logistic train acc: 0.994286, test acc: 1.000000\n",
      "\n",
      "Two Moon data\n",
      "perceptron train acc: 0.820000, test acc: 0.840000\n",
      "logistic train acc: 0.857143, test acc: 0.866667\n",
      "\n",
      "Binarized MNIST data\n",
      "perceptron train acc: 0.873400, test acc: 0.828000\n",
      "logistic train acc: 0.871000, test acc: 0.834000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_binary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_train(X, y, C,\n",
    "                     w0=None, \n",
    "                     b0=None,\n",
    "                     gd_type=\"sgd\",\n",
    "                     step_size=0.5, \n",
    "                     max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: training features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - y: multiclass training labels, a N dimensional numpy array where\n",
    "    N is the number of training points, indicating the labels of \n",
    "    training data\n",
    "    - C: number of classes in the data\n",
    "    - gd_type: gradient descent type, either GD or SGD\n",
    "    - step_size: step size (learning rate)\n",
    "    - max_iterations: number of iterations to perform gradient descent\n",
    "\n",
    "    Returns:\n",
    "    - w: C-by-D weight matrix of multinomial logistic regression, where \n",
    "    C is the number of classes and D is the dimensionality of features.\n",
    "    - b: bias vector of length C, where C is the number of classes\n",
    "    \"\"\"\n",
    "\n",
    "    N, D = X.shape\n",
    "\n",
    "    w = np.zeros((C, D))\n",
    "    if w0 is not None:\n",
    "        w = w0\n",
    "    \n",
    "    b = np.zeros(C)\n",
    "    if b0 is not None:\n",
    "        b = b0\n",
    "\n",
    "    np.random.seed(42)\n",
    "        \n",
    "    \n",
    "    if gd_type == \"sgd\":\n",
    "        ############################################\n",
    "        # TODO 6 : Edit this if part               #\n",
    "        #          Compute w and b                 #\n",
    "        w = np.zeros((C, D))\n",
    "        b = np.zeros(C)\n",
    "        \n",
    "        def softmax(x):\n",
    "            x = np.exp(x - np.max(x) )\n",
    "            return x / np.sum(x)\n",
    "        ############################################\n",
    "        for i in range(max_iterations):\n",
    "            xi = np.random.choice(N)\n",
    "            x = X[xi]  # 1 * 2\n",
    "            # yi = np.eye(C)[ y[xi] ] # 1 * C\n",
    "            yi = y[xi]\n",
    "            \n",
    "            err = softmax( x.dot(w.T) + b )  # c * 1\n",
    "            err[yi] = err[yi] - 1\n",
    "            w_c = -step_size * np.outer(err, x)  #  C * 2\n",
    "            b_c = -step_size * err  #  C\n",
    "            w = w + w_c\n",
    "            b = b + b_c\n",
    "        \n",
    "    elif gd_type == \"gd\":\n",
    "        ############################################\n",
    "        # TODO 7 : Edit this if part               #\n",
    "        #          Compute w and b                 #\n",
    "        w = np.zeros((C, D))\n",
    "        b = np.zeros(C)\n",
    "        \n",
    "        y = np.eye(C)[y] # create n * C \n",
    "        \n",
    "        # n * C \n",
    "        def softmax(x):\n",
    "            x = np.exp(x - np.max(x, axis=1).reshape((-1,1)))\n",
    "            return x / np.sum(x, axis=1).reshape((-1, 1))\n",
    "        ############################################\n",
    "        for i in range(max_iterations):\n",
    "            \n",
    "            err = softmax((X.dot(w.T).T + b.reshape((-1, 1))).T ) - y  # n*C\n",
    "            w_c = -step_size * err.T.dot(X)/ N  #  C * 2\n",
    "            b_c = -step_size * np.sum(err, axis=0) / N  #  C\n",
    "            w = w + w_c\n",
    "            b = b + b_c\n",
    "    \n",
    "    else:\n",
    "        raise \"Type of Gradient Descent is undefined.\"\n",
    "    \n",
    "\n",
    "    assert w.shape == (C, D)\n",
    "    assert b.shape == (C,)\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = np.exp(x - np.max(x, axis=1).reshape((-1, 1))   )\n",
    "    return x / np.sum(x, axis=1).reshape((-1, 1))\n",
    "\n",
    "\n",
    "def multiclass_predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: testing features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - w: weights of the trained multinomial classifier, C-by-D \n",
    "    - b: bias terms of the trained multinomial classifier, length of C\n",
    "    \n",
    "    Returns:\n",
    "    - preds: N dimensional vector of multiclass predictions.\n",
    "    Outputted predictions should be from {0, C - 1}, where\n",
    "    C is the number of classes\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    ############################################\n",
    "    # TODO 8 : Edit this part to               #\n",
    "    #          Compute preds                   #\n",
    "    preds = np.zeros(N)\n",
    "    ############################################\n",
    "    preds = softmax((X.dot(w.T).T + b.reshape((-1, 1))).T )\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    \n",
    "    assert preds.shape == (N,)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(5)[np.array([1,2,3,0,2,2,3,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(6)[[2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6,  7,  8],\n",
       "       [14, 15, 16, 17, 18]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.array(range(10)).reshape((2,5))\n",
    "D = np.max(C, axis = 1)\n",
    "C + D.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(C, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiclass():\n",
    "    from data_loader import toy_data_multiclass, \\\n",
    "                            data_loader_mnist \n",
    "    import time\n",
    "    datasets = [(toy_data_multiclass(), 'Toy Data multiclass', 3),\\\n",
    "                (data_loader_mnist(), 'MNIST', 10)]\n",
    "\n",
    "    for data, name, num_classes in datasets:\n",
    "        print('%s: %d class classification' % (name, num_classes))\n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        for gd_type in [\"sgd\", \"gd\"]:\n",
    "            s = time.time()\n",
    "            w, b = multiclass_train(X_train, y_train, C=num_classes, gd_type=gd_type)\n",
    "            print(gd_type + ' training time: %0.6f seconds' %(time.time()-s))\n",
    "                \n",
    "            #print(\"w:\", w)\n",
    "            #print(\"b:\", b)\n",
    "            \n",
    "            train_preds = multiclass_predict(X_train, w=w, b=b)\n",
    "            preds = multiclass_predict(X_test, w=w, b=b)\n",
    "            print('train acc: %f, test acc: %f' \n",
    "                % (accuracy_score(y_train, train_preds), accuracy_score(y_test, preds)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Data multiclass: 3 class classification\n",
      "sgd training time: 0.307604 seconds\n",
      "train acc: 0.948571, test acc: 0.948333\n",
      "gd training time: 0.155063 seconds\n",
      "train acc: 0.950000, test acc: 0.950000\n",
      "\n",
      "MNIST: 10 class classification\n",
      "sgd training time: 0.474897 seconds\n",
      "train acc: 0.819800, test acc: 0.800000\n",
      "gd training time: 3.918744 seconds\n",
      "train acc: 0.945400, test acc: 0.896000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_multiclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
