{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def data_processing_linear_regression(filename, non_invertible, mapping, mapping_power):\n",
    "  \n",
    "\n",
    "  white = pd.read_csv(filename, low_memory=False, sep=';').values\n",
    "\n",
    "  [N, d] = white.shape\n",
    "\n",
    "  if(mapping == True):\n",
    "    maped_X = mapping_data(white[:,:-1],mapping_power)\n",
    "    white = np.insert(maped_X, maped_X.shape[1], white[:,-1], axis=1)\n",
    "    \n",
    "\n",
    "  np.random.seed(3)\n",
    "  # prepare data\n",
    "  ridx = np.random.permutation(N)\n",
    "  ntr = int(np.round(N * 0.8))\n",
    "  nval = int(np.round(N * 0.1))\n",
    "  ntest = N - ntr - nval\n",
    "\n",
    "  # spliting training, validation, and test\n",
    "\n",
    "  Xtrain = np.hstack([np.ones([ntr, 1]), white[ridx[0:ntr], 0:-1]])\n",
    "\n",
    "  ytrain = white[ridx[0:ntr], -1]\n",
    "\n",
    "  Xval = np.hstack([np.ones([nval, 1]), white[ridx[ntr:ntr + nval], 0:-1]])\n",
    "  yval = white[ridx[ntr:ntr + nval], -1]\n",
    "\n",
    "  Xtest = np.hstack([np.ones([ntest, 1]), white[ridx[ntr + nval:], 0:-1]])\n",
    "  ytest = white[ridx[ntr + nval:], -1]\n",
    "  if(non_invertible == True):\n",
    "    N, D = Xtrain.shape\n",
    "    np.random.seed(4)\n",
    "    random_row = np.random.randint(N)\n",
    "    random_col = np.random.randint(D)\n",
    "    \n",
    "    Xtrain[:,random_col] = 0\n",
    "    Xtrain[random_row,:] = 0\n",
    "    \n",
    "    return Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "  return Xtrain, ytrain, Xval, yval, Xtest, ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(w, X, y):\n",
    "    \"\"\"\n",
    "    Compute the mean absolute error on test set given X, y, and model parameter w.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing test feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing test label\n",
    "    - w: a numpy array of shape (D, )\n",
    "    Returns:\n",
    "    - err: the mean absolute error\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    # TODO 1: Fill in your code here #\n",
    "    #####################################################\n",
    "    err = None\n",
    "    num_samples = y.shape[0]\n",
    "    err = np.sum(abs(X.dot(w) - y))/num_samples\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_noreg(X, y):\n",
    "    w = np.linalg.inv(np.dot(X.T, X)).dot(X.T).dot(y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Question 1.1 and Question 1.2 ========\n",
      "dimensionality of the model parameter is (12,).\n",
      "model parameter is  [ 2.03721116e+02  1.09955585e-01 -1.93164831e+00 -4.90845226e-02\n",
      "  1.02194195e-01 -5.45232539e-02  4.00189586e-03  1.52537227e-04\n",
      " -2.04673020e+02  9.04608186e-01  6.41578532e-01  1.32320100e-01]\n",
      "MAE on train is 0.58020\n",
      "MAE on val is 0.59410\n",
      "MAE on test is 0.56079\n"
     ]
    }
   ],
   "source": [
    "filename = 'winequality-white.csv'\n",
    "\n",
    "print(\"\\n======== Question 1.1 and Question 1.2 ========\")\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, False, False, 0)\n",
    "w = linear_regression_noreg(Xtrain, ytrain)\n",
    "print(\"dimensionality of the model parameter is \", w.shape, \".\", sep=\"\")\n",
    "print(\"model parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is %.5f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Q1.3 ######\n",
    "def linear_regression_invertible(X, y):\n",
    "    \"\"\"\n",
    "    Compute the weight parameter given X and y.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing label\n",
    "    Returns:\n",
    "    - w: a numpy array of shape (D, )\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    # TODO 3: Fill in your code here #\n",
    "    #####################################################\n",
    "    w = None\n",
    "    cnt = 1\n",
    "    XTX = X.T.dot(X)\n",
    "    while(abs(np.min(np.linalg.eigvals(XTX + cnt * np.eye(XTX.shape[0]))))< pow(10, -5)):\n",
    "        cnt += 1\n",
    "    XTX = XTX + cnt * np.eye(XTX.shape[0])\n",
    "    w = np.linalg.inv(XTX).dot(X.T).dot(y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Question 1.3 ========\n",
      "dimensionality of the model parameter is (12,).\n",
      "model parameter is  [ 0.84355506 -0.04441418 -2.00890117 -0.11681133  0.0285244  -0.48792001\n",
      "  0.00431189  0.          0.66002924  0.24521302  0.350988    0.38109447]\n",
      "MAE on train is 0.58522\n",
      "MAE on val is 0.60007\n",
      "MAE on test is 0.55819\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n======== Question 1.3 ========\")\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, True, False, 0)\n",
    "w = linear_regression_invertible(Xtrain, ytrain)\n",
    "print(\"dimensionality of the model parameter is \", w.shape, \".\", sep=\"\")\n",
    "print(\"model parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is %.5f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Q1.4 ######\n",
    "def regularized_linear_regression(X, y, lambd):\n",
    "    \"\"\"\n",
    "    Compute the weight parameter given X, y and lambda.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing label\n",
    "    - lambd: a float number containing regularization strength\n",
    "    Returns:\n",
    "    - w: a numpy array of shape (D, )\n",
    "    \"\"\"\n",
    "  #####################################################\n",
    "  # TODO 4: Fill in your code here #\n",
    "  #####################################################\t\t\n",
    "    w = None\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX += lambd * np.eye(XTX.shape[0])\n",
    "    w = np.linalg.inv(XTX).dot(X.T).dot(y)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Question 1.4 ========\n",
      "dimensionality of the model parameter is (12,).\n",
      "model parameter is  [ 1.72490981 -0.04898016 -2.05742338 -0.12068529  0.02838304 -0.81308859\n",
      "  0.00425276  0.          0.00675103  0.20653332  0.35756603  0.37653797]\n",
      "MAE on train is 0.58509\n",
      "MAE on val is 0.59939\n",
      "MAE on test is 0.55777\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n======== Question 1.4 ========\")\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, True, False, 0)\n",
    "w = regularized_linear_regression(Xtrain, ytrain, 0.1)\n",
    "print(\"dimensionality of the model parameter is \", w.shape, \".\", sep=\"\")\n",
    "print(\"model parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is %.5f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Q1.5 ######\n",
    "def tune_lambda(Xtrain, ytrain, Xval, yval):\n",
    "    \"\"\"\n",
    "    Find the best lambda value.\n",
    "    Inputs:\n",
    "    - Xtrain: A numpy array of shape (num_training_samples, D) containing training feature.\n",
    "    - ytrain: A numpy array of shape (num_training_samples, ) containing training label\n",
    "    - Xval: A numpy array of shape (num_val_samples, D) containing validation feature.\n",
    "    - yval: A numpy array of shape (num_val_samples, ) containing validation label\n",
    "    Returns:\n",
    "    - bestlambda: the best lambda you find in lambds\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    # TODO 5: Fill in your code here #\n",
    "    #####################################################\t\t\n",
    "    bestlambda = None\n",
    "    mae = float('inf')\n",
    "    for lamda in range(-19, 20):\n",
    "        w = regularized_linear_regression(Xtrain, ytrain, pow(10, lamda))\n",
    "        if mean_absolute_error(w, Xval, yval) < mae:\n",
    "            bestlambda = pow(10, lamda)\n",
    "    return bestlambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Question 1.5========\n",
      "Best Lambda =  0.1\n",
      "dimensionality of the model parameter is 12.\n",
      "model parameter is  [ 1.67492616e+00 -4.46761693e-02 -2.00550032e+00 -1.08678263e-01\n",
      "  2.92199160e-02 -7.64112758e-01  5.23116206e-03 -7.54594811e-04\n",
      "  5.17634041e-02  2.30856732e-01  3.78135271e-01  3.70053691e-01]\n",
      "MAE on train is 0.58255\n",
      "MAE on val is 0.60029\n",
      "MAE on test is 0.55552\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n======== Question 1.5========\")\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, False, False, 0)\n",
    "bestlambd = tune_lambda(Xtrain, ytrain, Xval, yval)\n",
    "print(\"Best Lambda =  \" + str(bestlambd))\n",
    "w = regularized_linear_regression(Xtrain, ytrain, bestlambd)\n",
    "print(\"dimensionality of the model parameter is \", len(w), \".\", sep=\"\")\n",
    "print(\"model parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is %.5f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
